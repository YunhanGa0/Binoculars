# HC3è‹±æ–‡æ•°æ®é›†è¯„ä¼°æŒ‡å—

## ğŸ“‹ é¡¹ç›®è¯´æ˜

æœ¬é¡¹ç›®ç”¨äºåœ¨HC3è‹±æ–‡æ•°æ®é›†ä¸Šè¯„ä¼°Binocularsæ–¹æ³•çš„AIæ–‡æœ¬æ£€æµ‹æ€§èƒ½ã€‚

## ğŸ¯ å…³äºåŒæ¨¡å‹é…ç½®

### â“ å¿…é¡»ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹

Binocularsä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹è®¡ç®—æ£€æµ‹åˆ†æ•°ï¼š

```
Binoculars Score = Perplexity(Performer) / Cross-Entropy(Observer, Performer)
```

**ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹ï¼Ÿ**

- **Observeræ¨¡å‹**ï¼šæä¾›å‚è€ƒè§†è§’
- **Performeræ¨¡å‹**ï¼šè¯„ä¼°æ–‡æœ¬è´¨é‡
- ä¸¤ä¸ªæ¨¡å‹çš„å·®å¼‚æ˜¯æ£€æµ‹çš„å…³é”®ï¼š
  - AIæ–‡æœ¬ï¼šä¸¤ä¸ªæ¨¡å‹é¢„æµ‹ä¸€è‡´ â†’ åˆ†æ•°é«˜ï¼ˆæ¥è¿‘1.0ï¼‰
  - äººç±»æ–‡æœ¬ï¼šä¸¤ä¸ªæ¨¡å‹é¢„æµ‹æœ‰å·®å¼‚ â†’ åˆ†æ•°ä½

**æ¨èé…ç½®ï¼š**

| åœºæ™¯ | Observer | Performer | GPUéœ€æ±‚ | è¯´æ˜ |
|------|----------|-----------|---------|------|
| é«˜æ€§èƒ½ï¼ˆé»˜è®¤ï¼‰âœ… | `EleutherAI/gpt-neo-1.3B` | `EleutherAI/gpt-neo-2.7B` | 8GB | RTX 2070Sçº§åˆ« |
| å¹³è¡¡æ€§èƒ½ | `gpt2-medium` | `EleutherAI/gpt-neo-1.3B` | 4-6GB | ä¸­ç­‰æ˜¾å¡ |
| è½»é‡çº§ | `gpt2` | `gpt2-medium` | 2GB | èµ„æºæœ‰é™æ—¶ |
| æœ€ä½³ï¼ˆéœ€å¤§GPUï¼‰ | `tiiuae/falcon-7b` | `tiiuae/falcon-7b-instruct` | 16GB+ | 7Bå‚æ•° |

è¯¦ç»†åŸç†è¯·å‚è€ƒï¼š[DUAL_MODEL_EXPLANATION.md](DUAL_MODEL_EXPLANATION.md)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install datasets transformers torch scikit-learn matplotlib pandas
```

### 2. å‡†å¤‡HC3è‹±æ–‡æ•°æ®é›†

```bash
python experiments/hc3_loader.py
```

è¿™å°†ä¸‹è½½å¹¶æ ¼å¼åŒ–HC3è‹±æ–‡æ•°æ®é›†åˆ° `datasets/hc3/hc3_english_qa.jsonl`

### 3. è¿è¡Œè¯„ä¼°

#### å¿«é€Ÿæµ‹è¯•ï¼ˆ100æ ·æœ¬ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

```bash
# ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼šgpt-neo-1.3B + gpt-neo-2.7Bï¼ˆé«˜æ€§èƒ½ï¼Œéœ€è¦8GBæ˜¾å­˜ï¼‰
python experiments/run_hc3_evaluation.py \
    --dataset_path datasets/hc3/hc3_english_qa.jsonl \
    --max_samples 100
```

#### å®Œæ•´è¯„ä¼°ï¼ˆå…¨æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼šgpt-neo-1.3B + gpt-neo-2.7Bï¼ˆé€‚åˆRTX 2070Sç­‰8GBæ˜¾å¡ï¼‰
python experiments/run_hc3_evaluation.py \
    --dataset_path datasets/hc3/hc3_english_qa.jsonl \
    --output_dir results/hc3_full_evaluation
```

#### é«˜æ€§èƒ½è¯„ä¼°ï¼ˆéœ€è¦å¤§GPUï¼Œä½¿ç”¨Falconæ¨¡å‹ï¼‰

```bash
# ä»…åœ¨æœ‰16GB+æ˜¾å­˜æ—¶ä½¿ç”¨
python experiments/run_hc3_evaluation.py \
    --dataset_path datasets/hc3/hc3_english_qa.jsonl \
    --observer tiiuae/falcon-7b \
    --performer tiiuae/falcon-7b-instruct \
    --batch_size 8 \
    --use_bfloat16 \
    --output_dir results/hc3_falcon_evaluation
```

#### ä½¿ç”¨Windowsè„šæœ¬

```bash
run_hc3_eval.bat
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

è¯„ä¼°å®Œæˆåä¼šè¾“å‡ºä»¥ä¸‹æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Accuracy** | æ•´ä½“å‡†ç¡®ç‡ |
| **Precision** | ç²¾ç¡®ç‡ï¼ˆæ£€æµ‹ä¸ºAIçš„æ–‡æœ¬ä¸­çœŸæ­£æ˜¯AIçš„æ¯”ä¾‹ï¼‰ |
| **Recall** | å¬å›ç‡ï¼ˆæ‰€æœ‰AIæ–‡æœ¬ä¸­è¢«æ­£ç¡®æ£€æµ‹çš„æ¯”ä¾‹ï¼‰ |
| **F1-Score** | F1åˆ†æ•°ï¼ˆç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼‰ |
| **ROC-AUC** | ROCæ›²çº¿ä¸‹é¢ç§¯ |
| **TPR@FPR=0.01%** | åœ¨æä½è¯¯æŠ¥ç‡ï¼ˆ0.01%ï¼‰ä¸‹çš„çœŸæ­£ä¾‹ç‡ |
| **FPR@TPR=95%** | åœ¨95%å¬å›ç‡ä¸‹çš„è¯¯æŠ¥ç‡ |

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è¯„ä¼°ç»“æœä¿å­˜åœ¨ `results/` ç›®å½•ï¼š

```
results/hc3_eval_20260119_120000/
â”œâ”€â”€ metrics_summary.json       # æŒ‡æ ‡æ‘˜è¦
â”œâ”€â”€ detailed_scores.csv        # æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ•°
â”œâ”€â”€ roc_curve.png             # ROCæ›²çº¿å›¾
â””â”€â”€ score_distribution.png    # åˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾
```

## ğŸ”§ å‚æ•°è¯´æ˜

```bash
--dataset_path      # HC3æ•°æ®é›†è·¯å¾„ï¼ˆé»˜è®¤ï¼šdatasets/hc3/hc3_english_qa.jsonlï¼‰
--human_key         # äººç±»æ–‡æœ¬å­—æ®µåï¼ˆé»˜è®¤ï¼šhuman_sampleï¼‰
--chatgpt_key       # ChatGPTæ–‡æœ¬å­—æ®µåï¼ˆé»˜è®¤ï¼šchatgpt_generated_textï¼‰
--max_samples       # æœ€å¤§æ ·æœ¬æ•°ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•

--observer          # Observeræ¨¡å‹ï¼ˆé»˜è®¤ï¼šEleutherAI/gpt-neo-1.3Bï¼Œ1.3Bå‚æ•°ï¼‰
--performer         # Performeræ¨¡å‹ï¼ˆé»˜è®¤ï¼šEleutherAI/gpt-neo-2.7Bï¼Œ2.7Bå‚æ•°ï¼‰
--mode              # æ£€æµ‹æ¨¡å¼ï¼šaccuracy æˆ– low-fprï¼ˆé»˜è®¤ï¼šaccuracyï¼‰
--use_bfloat16      # ä½¿ç”¨bfloat16ç²¾åº¦ï¼ˆèŠ‚çœå†…å­˜ï¼‰

--tokens_seen       # æœ€å¤§tokenæ•°ï¼ˆé»˜è®¤ï¼š512ï¼‰
--batch_size        # æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š16ï¼‰
--output_dir        # ç»“æœè¾“å‡ºç›®å½•
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆRTX 2070Sç­‰8GBæ˜¾å¡ï¼‰

```bash
# é»˜è®¤ï¼šgpt-neo-1.3B + gpt-neo-2.7Bï¼Œé«˜æ€§èƒ½
python experiments/run_hc3_evaluation.py \
    --max_samples 50
```

### ç¤ºä¾‹2ï¼šä¸­ç­‰é…ç½®ï¼ˆ4-6GBæ˜¾å­˜ï¼‰

```bash
# å¦‚æœæ˜¯4-6GBæ˜¾å­˜ï¼Œä½¿ç”¨ä¸­ç­‰æ¨¡å‹
python experiments/run_hc3_evaluation.py \
    --observer gpt2-medium \
    --performer EleutherAI/gpt-neo-1.3B \
    --batch_size 8
```

### ç¤ºä¾‹3ï¼šä½¿ç”¨Falconæ¨¡å‹ï¼ˆåŸè®ºæ–‡é…ç½®ï¼‰

```bash
python experiments/run_hc3_evaluation.py \
    --observer tiiuae/falcon-7b \
    --performer tiiuae/falcon-7b-instruct \
    --batch_size 8 \
    --use_bfloat16
```

### ç¤ºä¾‹4ï¼šè‡ªå®šä¹‰GPT-Neoæ¨¡å‹

```bash
python experiments/run_hc3_evaluation.py \
    --observer EleutherAI/gpt-neo-1.3B \
    --performer EleutherAI/gpt-neo-2.7B \
    --batch_size 8
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### GPUå†…å­˜ä¸è¶³

```bash
# å‡å°batch_size
--batch_size 4

# å‡å°‘tokenæ•°
--tokens_seen 256

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
--observer gpt2 --performer gpt2-medium

# å¯ç”¨bfloat16
--use_bfloat16
```

### æ¨¡å‹ä¸‹è½½æ…¢

```python
# è®¾ç½®HuggingFaceé•œåƒ
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

### æ•°æ®é›†åŠ è½½å¤±è´¥

æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½HC3æ•°æ®é›†åˆ°æœ¬åœ°ï¼š

```python
from datasets import load_dataset
dataset = load_dataset("Hello-SimpleAI/HC3")
dataset.to_json("datasets/hc3/hc3_manual.jsonl")
```

## ğŸ“ˆ é¢„æœŸç»“æœ

åœ¨HC3è‹±æ–‡æ•°æ®é›†ä¸Šï¼ŒBinocularsï¼ˆä½¿ç”¨Falcon-7Bé…ç½®ï¼‰çš„å…¸å‹æ€§èƒ½ï¼š

- **Accuracy**: ~85-90%
- **F1-Score**: ~85-88%
- **ROC-AUC**: ~0.92-0.95

ä½¿ç”¨ä¸åŒæ¨¡å‹é…ç½®ä¼šæœ‰ä¸åŒçš„æ€§èƒ½è¡¨ç°ã€‚

## ğŸ“ å®éªŒæµç¨‹å»ºè®®

1. **ç¬¬ä¸€æ­¥ï¼šå¿«é€ŸéªŒè¯ï¼ˆ10åˆ†é’Ÿï¼‰**
   ```bash
   --max_samples 100 --observer gpt2 --performer gpt2-medium
   ```

2. **ç¬¬äºŒæ­¥ï¼šä¸­ç­‰è§„æ¨¡æµ‹è¯•ï¼ˆ30åˆ†é’Ÿï¼‰**
   ```bash
   --max_samples 1000 --observer gpt2-medium --performer gpt2-large
   ```

3. **ç¬¬ä¸‰æ­¥ï¼šå®Œæ•´è¯„ä¼°ï¼ˆ1-2å°æ—¶ï¼‰**
   ```bash
   # ä½¿ç”¨å®Œæ•´æ•°æ®é›†å’Œæœ€ä½³æ¨¡å‹
   --observer tiiuae/falcon-7b --performer tiiuae/falcon-7b-instruct
   ```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [åŒæ¨¡å‹åŸç†è¯¦è§£](DUAL_MODEL_EXPLANATION.md)
- [å®Œæ•´å®ç°æ€»ç»“](HC3_IMPLEMENTATION_SUMMARY.md)
- [å®éªŒæŒ‡å—](HC3_EXPERIMENT_GUIDE.md)

## ğŸ”— æ•°æ®é›†å’Œè®ºæ–‡

- **HC3æ•°æ®é›†**: [HuggingFace](https://huggingface.co/datasets/Hello-SimpleAI/HC3)
- **HC3è®ºæ–‡**: [How Close is ChatGPT to Human Experts?](https://arxiv.org/abs/2301.07597)
- **Binocularsè®ºæ–‡**: [Spotting LLMs with Binoculars](https://arxiv.org/abs/2401.12070)

## âœ¨ ç»“æœç¤ºä¾‹

è¯„ä¼°å®Œæˆåï¼Œæ§åˆ¶å°è¾“å‡ºç¤ºä¾‹ï¼š

```
================================================================================
HC3 Evaluation Results
================================================================================
Dataset: HC3 English
Observer Model: tiiuae/falcon-7b
Performer Model: tiiuae/falcon-7b-instruct
Total Samples: 24322
--------------------------------------------------------------------------------
Accuracy:        0.8765
Precision:       0.8821
Recall:          0.8709
F1-Score:        0.8765
ROC-AUC:         0.9423
TPR@FPR=0.01%:   0.7856
FPR@TPR=95%:     0.0812
================================================================================
```

ç¥è¯„ä¼°é¡ºåˆ©ï¼ğŸ‰
